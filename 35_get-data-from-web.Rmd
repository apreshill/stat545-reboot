# (PART) Get data from the web {-} 

# Introduction {-#api-intro} 

Accompanying slides are [here](http://stat545.com/webdata01_slides.html)


There are many ways to obtain data from the Internet; let's consider four categories:

1. **Click-and-download** on the internet as a "flat" file, such as .csv, .xls
2. **Install-and-play** an API for which someone has written a handy R package (i.e. an API-wrapping package)
3. **API-query** published with an unwrapped API
4. **Scraping** implicit in an html website


Many times, the data that you want is not already organized into one or a few tables that you can read directly into R. More frequently, you find this data is given in the form of an API. 

**A**pplication **P**rogramming **I**nterfaces (APIs) are descriptions of the kind of requests that can be made of a certain piece of software, and descriptions of the kind of answers that are returned. 

Many sources of data -- databases, websites, services -- have made all (or part) of their data available via APIs over the internet. Computer programs ("clients") can make requests of the server, and the server will respond by sending data (or an error message). This client can be many kinds of other programs or websites, including R running from your laptop.


All this and more is described at the [rOpenSci repository of R tools for interacting with the internet](https://github.com/ropensci/webservices).

* `downloader::download()` for SSL
* `curl::curl()` for SSL.
* `httr::GET` data read this way needs to be parsed later with read.table
* `rio::import()` can "read a number of common data formats directly from an https:// URL".  Isn't that very similar to the previous?

